---
title: "Time series analysis assignment"
format: html
editor: visual
---

# Exponential smoothing

### Fitting a exponential smoother

For daliy stock data like the DOW stock, it is sutible to use a Holt-Winters method. Stock prices most often shows a trend but not as often a fixed daily seasonality that monthly data does. By using the Holt-Winters method we are able to visualize the underlying trend of the DOWÂ´s development.

To begin with, in order to implement the Holt-Winters method we need to create a time series object.

```{r}
dow_ts <- ts(dow_price$close, start = 2019, frequency = 252)
```

By using the ts argument in R-studio we are able to convert the dataframe dow_price to a time series. The next step is to fit the Holt-Winters method with no seasonality and then the final step is to plot the observed data versus the fitted values of the Holt-Winters method.

```{r}
hw_dow <- HoltWinters(dow_ts, gamma = FALSE)

plot(hw_dow, main = "Plot 5: DOW Stock Price: Observed Values vs Fitted Values")
legend("topright",
       legend = c("Observed", "Fitted"),
       col = c("black", "red"),
       lty = 1,
       cex = 0.5)
```

As seen in plot 5 the fitted values follows the observed data very closley. This tends to be the case when smoothing volatile data, it often looks like the fitted values are lagging one step behind. This means that model estimates for the stock price for the DOW today has a heavy influence of the price from yesterday.

The smoothing parameters play a big part in the behavior of the red line. By looking at plot 5 we can determine that the level(a) must be high since the fitted line follows the observed line closely. This means that the model gives much weight to the most recent observations. We can see that the trend parameter is weak since the fitted values tend to follow the observed data rather than following a general direction.

### Rolling forecasts

In order to determine the predictive power of our HW model, rolling forecasts for the final 30 observations of the dataset is to be made. It makes it possible for the model to re-estimate the smoothing parameters as new data points are available.The code used is a function made so that the rolling forecasts are automatic.

```{r}
# Function for rolling forecasts
dow_rolling_forecasts <- function(data, n_test, horizon) {
  n_total <- length(data)
  preds <- numeric(n_test)
  
  for (i in 1:n_test) {
    train_end <- n_total - n_test + i - 1
    train_ts <- ts(data[1:train_end],
                   start = start(data),
                   frequency = frequency(data))
    train_fit <- HoltWinters(train_ts, gamma = FALSE)
    predicitions <- predict(train_fit, n.ahead = horizon)
    preds[i] <- predicitions[horizon]
  }
  final_results <- ts(preds,
             start = time(data)[n_total - n_test + 1],
             frequency = frequency(data))
  return(final_results)
}

```

Now that the function is defined we can make the rolling forecasts for the horizons h=1 and h=4 since our time series does not have any seasonality.

```{r}
rf_dow_h1 <- dow_rolling_forecasts(dow_ts, n_test = 30, horizon = 1)
rf_dow_h4 <- dow_rolling_forecasts(dow_ts, n_test = 30, horizon = 4)
```

The next step in the process is to calculate the root mean sqaure error(RMSE) and mean absolute deviation(MAD). First we extract the last 30 observations of the observed data in order to calculate forecasting errors.

```{r}
# First extract the observed values
n_total <- length(dow_ts)
observed_values <- window(dow_ts, start = time(dow_ts)[n_total - 29])

# Secondly calculate the forecastning errors
fr_error_h1 <- observed_values - rf_dow_h1
fr_error_h4 <- observed_values - rf_dow_h4

# Last step is to calculate RMSE and MAD
rmse_h1 <- sqrt(mean(fr_error_h1^2))
rmse_h4 <- sqrt(mean(fr_error_h4^2))

mad_h1 <- mean(abs(fr_error_h1))
mad_h4 <- mean(abs(fr_error_h4))

results_matris <- matrix(c(rmse_h1, mad_h1,
                           rmse_h4, mad_h4),
                         nrow = 2, byrow = TRUE)
colnames(results_matris) <- c("RMSE", "MAD")
rownames(results_matris) <- c("h=1", "h=4")

result_table <- as.table(results_matris)
result_table
```

As table shows both the RMSE and MAD is lower for the shorter horizon. This shows that our exponential smoother is more accurate at predicting the the next day than predicting 4 days into the future.

In order to plot the predictions together with the observed data we had to alter the function shown earlier in the report.

```{r}
# Updated function
dow_rolling_intervals <- function(data, n_test, horizon, manual_alpha = 0.8) {
  n_total <- length(data)
# Matrix to store the three columns fit, lower and upper  
  preds_matrix <- matrix(NA, nrow = n_test, ncol = 3)
  
  for (i in 1:n_test) {
    train_end <- n_total - n_test + i - 1
# Manual alpha added
    train_ts <- ts(data[1:train_end],
                   start = start(data),
                   frequency = frequency(data))
    train_fit <- HoltWinters(train_ts, alpha = manual_alpha, gamma = FALSE)
# Intervals added
    int <- predict(train_fit, n.ahead = horizon, prediction.interval = TRUE)
    preds_matrix[i, ] <- int[horizon, ]
  }
  starting_time <- time(data)[n_total - n_test + 1]
  freq <- frequency(data)
 
   return(list(fit = ts(preds_matrix[,1], start = starting_time, frequency = freq),
              lower = ts(preds_matrix[,2], start = starting_time, frequency = freq),
              upper = ts(preds_matrix[,3], start = starting_time, frequency = freq)))
}
```

In the updated function there is an addition in the Holt-Winters function that uses a manual alpha value. The value chosen was 0.8 to ensure the model responds well to the high volatility of the DOW stock.

```{r}
results_h1 <- dow_rolling_intervals(dow_ts, n_test = 30, horizon = 1, manual_alpha = 0.8)
results_h4 <- dow_rolling_intervals(dow_ts, n_test = 30, horizon = 4, manual_alpha = 0.8)

start_test <- time(dow_ts)[length(dow_ts) -29]

ts.plot(dow_ts, results_h1$fit, results_h1$lower, results_h1$upper,
        col = c("black", "steelblue", "green", "green"),
        lty = c(1, 1, 2, 2),
        main = "Plot 6: Rolling Forecast Evalutation (h=1)",
        xlim = c(start_test - 0.05, start_test + 0.1),
        ylab = "Price")

legend("topright", legend = c("Observed", "Forecast", "95% CI"),
       col = c("black", "steelblue", "green", "green"), lty = c(1, 1, 2), cex = 0.8)

ts.plot(dow_ts, results_h4$fit, results_h4$lower, results_h4$upper,
        col = c("black", "steelblue", "green", "green"),
        lty = c(1, 1, 2, 2),
        main = "Plot 7: Rolling Forecast Evalutation (h=4)",
        xlim = c(start_test - 0.05, start_test + 0.1),
        ylab = "Price")

legend("topright", legend = c("Observed", "Forecast", "95% CI"),
       col = c("black", "steelblue", "green", "green"), lty = c(1, 1, 2), cex = 0.8)

```

Plot 6 and Plot 7 shows the rolling forecasts for horizons 1 and 4. With alpha being 0.8 the model is reactive to the volatility of the stock. As we could expect the interval for the prediction of the h=4 horizon the interval is wider than the h=1 horizon. It shows that the uncertainty increases as we make longer term forecast which was also show in the RMSE that rose from about 0.54 to 0.58.

### Comparing the Holt-Winters model with a Random Walk

```{r}
n_total <- length(dow_ts)
observed_values <- dow_ts[(n_total - 29):n_total]

# Random walk for h=1 and h=4
rw_h1_predi <- dow_ts[(n_total-30):(n_total-1)]
rw_h4_predi <- dow_ts[(n_total-33):(n_total-4)]

# Random walk errors
rw_error_h1 <- observed_values - rw_h1_predi
rw_error_h4 <- observed_values - rw_h4_predi

# Random walk RMSE
rw_rmse_h1 <- sqrt(mean(rw_error_h1^2))
rw_rmse_h4 <- sqrt(mean(rw_error_h4^2))

# Table to compare the results
RMSE_matrix <- matrix(c(rmse_h1, rw_rmse_h1,
                        rmse_h4, rw_rmse_h4),
                        nrow = 2, byrow = TRUE)
colnames(RMSE_matrix) <- c("HW RMSE", "RW RMSE")
rownames(RMSE_matrix) <- c("HW and RW h=1", "HW and RW h=4")
RMSE_table <- as.table(RMSE_matrix)
RMSE_table
```

By comparing the Holt-Winters model against the Random Walk model the results from the table shows that the Random Walk provides a slight improvement to forecasting on the horizon h=1. Though the Random Walks RMSE increases far more than the Holt-Winters model on the horizon h=4. This demonstrates that the Holt-Winters model is superior in catching the underlying trend of the DOW stock price over longer time periods compared to a Random Walk model.

# Stationarity 

The next step in the process is to look in to the stationarity of our time series. The purpose of determining stationarity is to look at the mean and the variance and see if they remain constant through out the time series. It is a cruical requirement for advanced time series models. In order to determine wheter the DOW index is stationary or not we will use an Augmented Dickey-Fuller test to see if the time series needs transformations in order to be stationary.

```{r}
plot(
  dow_ts,
  xlab = "",
  ylab = "Closing Price",
  main = " Plot 9: DOW stock price"
)
```

Looking at plot 9 we see that there is a slight trend to the time series and that in consequence tells us that it might not be stationary. To confirm this we use a ADF test that will show us if the time series is stationary or not.

```{r}
# ADF test with significance level of 0.05
adf.test(dow_ts)
```

The null hypothesis is that the series is non-stationary and the alternative hypothesis is that the time series is stationary. The p-value of the ADF test was 0.7273 which means we can not reject the null hypothesis since 0.7273\>0.05. This means that there is no statistical evidence that our time series is stationary and it requires transfromation in order to achive stationarity.

```{r}
# First order differencing
dow_ts_stationarity <- diff(dow_ts)

# Complete a ADF test agian
adf.test(dow_ts_stationarity)
```

By using a first-order differencing we see that the p-value is smaller than 0.01. This means we are able to reject the null hypothesis and assume that our time series is now stationary which will enable further analysis of the Dow stock price.

```{r}
# The stationary time series plot
plot(dow_ts_stationarity,
     main = "Plot 8: Stationary Time Series of the DOW index",
     ylab = "Change in Price",
     col = "steelblue3")

# The correlogram
acf(dow_ts_stationarity,
    main = "Plot 9: Correlogram of The Stationary DOW Index")
```

In plot 9 we see that the transformed DOW index is stationary. After applying the first order differencing the unit root that was present during the first ADF test on the non-stationary time series have now been removed. Looking att the auto correlation function we see that by using a first order differencing the residual are now independently and identically distributed(IID), a crucial requirment for the continued analysis.
